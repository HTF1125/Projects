"""ROBERT"""
import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
from robo.db import get_engine
from web.pages.base import BasePage


saa_codes = [
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Í∏∞ÌÉÄ/ÏÇ¨Î™®Ìà¨Ïûê_PD-Ïù∏ÏàòÍ∏àÏúµ",
    "Ïù¥ÏûêÏàòÏùµ_Ìï¥Ïô∏Ï±ÑÍ∂å_Íµ¨Ï°∞ÌôîÏ±ÑÍ∂å_Íµ¨Ï°∞ÌôîÏ±ÑÍ∂å",
    "Ïù¥ÏûêÏàòÏùµ_Ìï¥Ïô∏Ï±ÑÍ∂å_Sovereign/Financial_Sovereign",
    "Ïù¥ÏûêÏàòÏùµ_Ìï¥Ïô∏Ï±ÑÍ∂å_Sovereign/Financial_Financial",
    "Ïù¥ÏûêÏàòÏùµ_Ìï¥Ïô∏Ï±ÑÍ∂å_Sovereign/Financial_Quasi-Sovereign/Muni",
    "Ïù¥ÏûêÏàòÏùµ_Ìï¥Ïô∏Ï±ÑÍ∂å_ÌöåÏÇ¨Ï±Ñ/ÏÇ¨Î™®ÏÇ¨Ï±Ñ_ÌöåÏÇ¨Ï±Ñ",
    "Ïù¥ÏûêÏàòÏùµ_Ìï¥Ïô∏Ï±ÑÍ∂å_ÌöåÏÇ¨Ï±Ñ/ÏÇ¨Î™®ÏÇ¨Ï±Ñ_ÏÇ¨Î™®ÏÇ¨Ï±Ñ",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Ïù∏ÌîÑÎùº_Ïã†Ïû¨ÏÉù",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Ïù∏ÌîÑÎùº_Î∞úÏ†Ñ",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Ïù∏ÌîÑÎùº_Í∏∞ÌÉÄ-SOC",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Ïù∏ÌîÑÎùº_BTOBOT",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Ïù∏ÌîÑÎùº_BTL",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Î∂ÄÎèôÏÇ∞_Î∂ÄÎèôÏÇ∞Îã¥Î≥¥",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Î∂ÄÎèôÏÇ∞_Î∂ÄÎèôÏÇ∞PF",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Í∏∞ÌÉÄ/ÏÇ¨Î™®Ìà¨Ïûê_ÏÉÅÌíàÌà¨Ïûê",
    "Ïù¥ÏûêÏàòÏùµ_ÎåÄÏ≤¥Ìà¨Ïûê_Í∏∞ÌÉÄ/ÏÇ¨Î™®Ìà¨Ïûê_Í∏∞ÌÉÄ-ÏÇ¨Î™®Ìà¨Ïûê",
    "Ïù¥ÏûêÏàòÏùµ_Íµ≠ÎÇ¥Ï±ÑÍ∂å_ÌöåÏÇ¨Ï±Ñ/ÏÇ¨Î™®ÏÇ¨Ï±Ñ_ÌöåÏÇ¨Ï±Ñ",
    "Ïù¥ÏûêÏàòÏùµ_Íµ≠ÎÇ¥Ï±ÑÍ∂å_ÌöåÏÇ¨Ï±Ñ/ÏÇ¨Î™®ÏÇ¨Ï±Ñ_ÏÇ¨Î™®ÏÇ¨Ï±Ñ",
    "Ïù¥ÏûêÏàòÏùµ_Íµ≠ÎÇ¥Ï±ÑÍ∂å_ÌäπÏàò/Í∏àÏúµÏ±Ñ_Í∏àÏúµÏ±Ñ",
    "Ïù¥ÏûêÏàòÏùµ_Íµ≠ÎÇ¥Ï±ÑÍ∂å_Íµ¨Ï°∞ÌôîÏ±ÑÍ∂å_Íµ¨Ï°∞ÌôîÏ±ÑÍ∂å",
    "Ïù¥ÏûêÏàòÏùµ_Íµ≠ÎÇ¥Ï±ÑÍ∂å_Ï±ÑÍ∂åÌòï ÏàòÏùµÏ¶ùÍ∂å_Í∏∞ÌÉÄ",
    "Ïù¥ÏûêÏàòÏùµ_Íµ≠ÎÇ¥Ï±ÑÍ∂å_Îß§ÏûêÎãå_Í∏∞ÌÉÄ",
    "ÏàòÏùµÏ∂îÍµ¨_Ï£ºÏãù_ÏÉÅÏû•/Ï£ºÏãùÌòï ÏàòÏùµÏ¶ùÍ∂å_Í∏∞ÌÉÄ",
    "ÏàòÏùµÏ∂îÍµ¨_Ï£ºÏãù_ÎπÑÏÉÅÏû•/PEF_Í∏∞ÌÉÄ",
    "ALM_Ïú†ÎèôÏÑ±_Îã®Í∏∞ÏûêÍ∏à_Í∏∞ÌÉÄ",
    "ALM_Íµ≠ÎÇ¥Ï±ÑÍ∂å_Íµ≠Í≥†Ï±Ñ_Í∏∞ÌÉÄ",
    "Í∏∞ÌÉÄ_Í∏∞ÌÉÄ_Í∏∞ÌÉÄ_Í∏∞ÌÉÄ",
]


as_of_date = "Í∏∞Ï§ÄÏùºÏûê"
inception_date = "Î∞úÌñâÏùº"
maturity_date = "ÎßåÍ∏∞ÏùºÏûê"
last_coupon_date = "ÏßÅÏ†ÑÏù¥ÏûêÏùº"

position_id = "Ìè¨ÏßÄÏÖòID"
asset_classification = "ÏûêÏÇ∞Íµ¨Î∂ÑÎ™Ö"
security_classification = "Ïú†Í∞ÄÏ¶ùÍ∂åÎ∂ÑÎ•òÎ™Ö"
performance_classification = "Ïã§Ï†ÅÎ∂ÑÎ•òÏΩîÎìú"
portfolio_type = "Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ Ïù¥Î¶Ñ"
asset_class_1 = "ÏûêÏÇ∞Íµ∞1Î™Ö"
asset_class_2 = "ÏûêÏÇ∞Íµ∞2Î™Ö"
asset_class_3 = "ÏûêÏÇ∞Íµ∞3Î™Ö"
asset_class_4 = "ÏûêÏÇ∞Íµ∞4Î™Ö"
fixed_income_classification = "Ï±ÑÍ∂åÎ∂ÑÎ•òÎ™Ö"

applied_yield = "Ï†ÅÏö© ÏàòÏùµÎ•†"
face_yield = "Ïï°Î©¥Ïù¥ÏûêÏú®"

interest_periods = "Ïù¥ÏûêÏ£ºÍ∏∞"

book_value = "Ïû•Î∂ÄÍ∏àÏï°(ÏõêÌôî)"
face_value = "Ïï°Î©¥ Í∏àÏï°(ÏõêÌôî)"
fair_value = "Í≥µÏ†ïÍ∞ÄÏπò(ÏõêÌôî)"

product_type = "ÏÉÅÌíàÏú†ÌòïÎ™Ö"
product_name = "Ï¢ÖÎ™©Î™Ö"
account_name = "Ïö¥Ïö©ÌéÄÎìúÎ™Ö"
id_isin = "Íµ≠Ï†úÌëúÏ§ÄÏΩîÎìú"


@st.cache_data()
def read_bs() -> pd.DataFrame:
    data = pd.read_sql(
        sql="SELECT * FROM balance_sheet",
        con=get_engine(),
        parse_dates=[as_of_date, inception_date, maturity_date, last_coupon_date],
    )
    return data


@st.cache_data()
def read_cf() -> pd.DataFrame:
    data = pd.read_sql(
        sql="SELECT * FROM bs_cashflow",
        con=get_engine(),
        parse_dates=["date"],
    )
    return data


def get_frequency() -> str:
    return str(st.selectbox(label="Frequency", options=["D", "M", "Q", "Y"], index=3))


def get_start() -> str:
    return str(st.date_input(label="Start", value=pd.Timestamp("now")))


def get_end() -> str:
    return str(
        st.date_input(
            label="Start", value=pd.Timestamp("now") + pd.DateOffset(years=30)
        )
    )


class Manager(BasePage):
    def load_page(self):
        bs_data = read_bs()
        bs_data.insert(loc=0, column="Check", value=True)

        col1, col2 = st.columns(2)
        with col1:
            portfolio_type_options = bs_data[portfolio_type].unique()
            selected_portfolio_type = st.multiselect(
                label="Portflio Type",
                options=portfolio_type_options,
                default=portfolio_type_options,
            )
            bs_data = bs_data[
                bs_data[portfolio_type].isin(values=selected_portfolio_type)
            ]
        with col2:
            product_type_options = bs_data[product_type].unique()
            selected_portfolio_type = st.multiselect(
                label="Product Type",
                options=product_type_options,
                default=product_type_options,
            )
            bs_data = bs_data[
                bs_data[product_type].isin(values=selected_portfolio_type)
            ]

        col1, col2, col3 = st.columns(3)

        with col1:
            cfstart = get_start()

        with col2:
            cfend = get_end()

        with col3:
            frequency = get_frequency()

        with st.expander(label="See raw data", expanded=False):
            info_container = st.container()
            edited_df = st.data_editor(bs_data)  # üëà An editable dataframe
            final_df = edited_df[edited_df["Check"]]
            with info_container:
                st.info(f"Number of raw data cheked: {len(final_df)}/{len(edited_df)}")

        total_fair_value_data = final_df.groupby(by=product_type)[fair_value].sum()
        total_fair_value_data = total_fair_value_data[total_fair_value_data != 0]

        col1, col2 = st.columns([1, 2])
        with col1:
            if not bs_data.empty:
                self.h4("Current Asset Allocation:")
                fig = go.Figure(
                    data=[
                        go.Pie(
                            labels=total_fair_value_data.index,
                            values=total_fair_value_data.values,
                        )
                    ]
                )
                self.plotly(fig, height=600)

        cf_data = read_cf()
        cf_data["cashflow_amount"] /= 100_000_000
        cf_data = cf_data[cf_data["position_id"].isin(final_df[position_id])]

        if not cf_data.empty:
            with col2:
                self.h4("Future Cash Flow:")
                include_matuirty = st.checkbox(label="Include Principal", value=True)
                if not include_matuirty:
                    cf_data = cf_data[cf_data["cashflow_type"] != "principal"]

                cf_data = (
                    cf_data.groupby(by=["date", "product_type"])["cashflow_amount"]
                    .sum()
                    .unstack()
                )
                cf_data.replace(0, np.nan, inplace=True)

                cf_data = (
                    cf_data.resample(frequency)
                    .sum()
                    .loc[cfstart:cfend]
                    .dropna(how="all")
                )

                self.note("Îã®ÏúÑ: Ïñµ", align="right")
                ttcf = cf_data.sum(axis=1)
                fig = go.Figure()
                fig.add_trace(trace=go.Bar(x=ttcf.index, y=ttcf.values, name="Total"))
                fig.update_layout(barmode="stack", yaxis_tickformat=".2f")
                self.plotly(fig, height=200)
                fig = go.Figure()
                fig.update_traces([])
                for x in cf_data:
                    cf = cf_data[x].dropna()
                    fig.add_trace(trace=go.Bar(x=cf.index, y=cf.values, name=x))
                fig.update_layout(barmode="stack", yaxis_tickformat=".2f")
                self.plotly(fig, height=400)
        st.warning("SAA mapping ÌõÑ .... ÎπÑÏ§ëÌôïÏù∏ Í∏∞Îä• Í∞úÎ∞ú ÏòàÏ†ï")

        st.write(bs_data["saa_code"].unique())

        self.upload_excel()

    def read_excel(self, file) -> pd.DataFrame:
        try:
            return pd.read_excel(file)
        except Exception as e:
            st.error(f"An error occurred: {e}")
            return pd.DataFrame()

    def upload_excel(self) -> None:
        with st.expander("Upload New Data"):
            uploaded_file = st.file_uploader("Upload Balance Sheet", type=["xlsx"])

            if uploaded_file is not None:
                with st.spinner(text="Uploading in progress..."):
                    bs_data = self.read_excel(uploaded_file)

                    # Assuming all the column names exist in the DataFrame and have appropriate data
                    columns_to_concat = [
                        asset_classification,
                        product_type,
                        security_classification,
                        performance_classification,
                        asset_class_2,
                        asset_class_3,
                        asset_class_4,
                        fixed_income_classification,
                    ]

                    for column in columns_to_concat:
                        bs_data[column] = bs_data[column].fillna("")

                    bs_data["saa_code"] = (
                        bs_data[columns_to_concat]
                        .astype(str)
                        .apply(lambda row: "".join(row), axis=1)
                    )

                    # Handle missing values
                    bs_data["saa_code"] = bs_data["saa_code"].fillna(
                        ""
                    )  # Fill missing values with an empty string

                    st.write(bs_data)

                    if bs_data is not None:
                        bs_data.to_sql(
                            name="balance_sheet",
                            con=get_engine(),
                            if_exists="replace",
                            index=False,
                        )
                        st.cache_data.clear()
                        try:
                            saa_map = pd.read_sql(
                                sql="SELECT * FROM saa_mapping", con=get_engine()
                            )
                        except:
                            saa_map = pd.DataFrame(columns=["saa_code", "saa_custom"])

                        add_map = []
                        for saa_c in bs_data["saa_code"].unique():
                            if saa_c not in saa_map["saa_code"]:
                                add_map.append(
                                    {
                                        "saa_code": saa_c,
                                        "saa_custom": None,
                                    }
                                )

                        saa_map = pd.concat([saa_map, pd.DataFrame(add_map)])

                        saa_map.to_sql(
                            name="saa_map",
                            con=get_engine(),
                            if_exists="replace",
                            index=False,
                        )

                        cashflows = []
                        for _, bs_row in bs_data.iterrows():
                            if bs_row[product_type] in [
                                "Ïô∏Ìôò (FX)",
                                "ÌÜµÌôî Ïä§Ïôë(CRS)",
                                "Ï±ÑÍ∂åÏÑ†ÎèÑ",
                            ]:
                                continue

                            start = (
                                bs_row[last_coupon_date]
                                if pd.isna(bs_row[last_coupon_date])
                                else bs_row[as_of_date]
                                if pd.isna(bs_row[inception_date])
                                else bs_row[inception_date]
                            )
                            end = (
                                pd.Timestamp("now") + pd.DateOffset(years=10)
                                if pd.isna(bs_row[maturity_date])
                                else bs_row[maturity_date]
                            )
                            end = min(
                                end, pd.Timestamp("now") + pd.DateOffset(years=50)
                            )

                            periods = (
                                3
                                if bs_row[product_type] == "ÏàòÏùµÏ¶ùÍ∂å"
                                else 0
                                if bs_row[product_type] == "Ìï†Ïù∏Ï±Ñ"
                                else int(bs_row[interest_periods])
                            )

                            interest = int(bs_row[face_value] * bs_row[face_yield])
                            if interest == 0:
                                interest = int(
                                    bs_row[book_value] * bs_row[applied_yield]
                                )
                            interest = int(interest / 12 * periods / 100)
                            if (
                                interest != 0
                                and not pd.isna(start)
                                and not pd.isna(end)
                            ):
                                for date in pd.date_range(
                                    start=start,
                                    end=end,
                                    freq=pd.DateOffset(months=periods),
                                ):
                                    if date < pd.Timestamp("now"):
                                        continue

                                    cashflows.append(
                                        {
                                            "position_id": bs_row[position_id],
                                            "product_type": bs_row[product_type],
                                            "date": date,
                                            "cashflow_type": "interest",
                                            "cashflow_amount": interest,
                                        }
                                    )
                            if end is not None:
                                if end > pd.Timestamp("now"):
                                    cashflows.append(
                                        {
                                            "position_id": bs_row[position_id],
                                            "product_type": bs_row[product_type],
                                            "date": end,
                                            "cashflow_type": "principal",
                                            "cashflow_amount": bs_row[face_value]
                                            or bs_row[book_value],
                                        }
                                    )

                        cashflows = pd.DataFrame(cashflows)

                        cashflows.to_sql(
                            name="bs_cashflow",
                            con=get_engine(),
                            if_exists="replace",
                            index=False,
                        )
